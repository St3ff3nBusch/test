<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>LUMPI Labeling: LUMPI Labeling Tool</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LUMPI Labeling
   &#160;<span id="projectnumber">1</span>
   </div>
   <div id="projectbrief">Labelingtoolfor3Dboundingboxes</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">LUMPI Labeling Tool </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Code replacement</p>
<p><span id="operatin:tab"></span> <img src="images/operational_view.png" alt="Operational View" style="float: left;" class="inline"/></p>
<p>This tool is designed to label 3D bounding boxes in a point cloud with the use of different camera perspectives. It is configured to load the <a href="https://data.uni-hannover.de/en/dataset/lumpi">LUMPI dataset</a> and was used in the <a href="https://youtu.be/Ns6qsHsb06E">labeling process</a>.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
Content</h1>
<ul>
<li><a href="#installation">Installation</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#adaptation">Adaptation</a></li>
<li><a href="#development">Development</a></li>
<li><a href="#license">License</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md2"></a>
Installation</h1>
<p>The tool was developed and tested with Ubuntu 20.04, and following dependencies:</p><ul>
<li><a href="https://opencv.org/">OpenCV</a></li>
<li><a href="https://pointclouds.org/">Point Cloud Library</a></li>
<li><a href="https://www.qt.io/">QT</a></li>
</ul>
<p>You could install all dependencies by using the requirements.txt: </p><div class="fragment"><div class="line">$ xargs -a requirements.txt sudo apt-get install</div>
</div><!-- fragment --><p>Afterwards you could install this software by following these steps:</p>
<div class="fragment"><div class="line">$ git clone https://github.com/St3ff3nBusch/LUMPI-Labeling</div>
<div class="line">$ mkdir build</div>
<div class="line">$ cd build</div>
<div class="line">$ cmake &lt;LUMPI-Labeling-Path&gt;</div>
<div class="line">$ make</div>
<div class="line">$ ln -s &lt;LUMPI-Labeling-Path&gt; #This step is optional and is used to enable a dark color scheme for the tool.</div>
<div class="line">$ ./Labeling</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md3"></a>
Usage</h1>
<p>The primary purpose of this tool is to correct object tracks in LiDAR and camera data. Each track assumes a rigid bounding box, and currently, only rotation around the Z-axis (yaw/heading) is supported. The tool is preconfigured for the LUMPI dataset and requires the following <code>file structure</code><span id="structure"></span>:</p>
<ul>
<li>ROOT<ul>
<li>meta.json</li>
<li>Measurement**Id**<ul>
<li>lidar<ul>
<li>000000.ply</li>
<li>...</li>
</ul>
</li>
<li>cam<ul>
<li><b>deviceId</b><ul>
<li>video.mp4</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>An general overview is given in this video <a href="https://youtu.be/wgPDjPjT0bk">tutorial</a>.</p>
<h1><a class="anchor" id="autotoc_md4"></a>
Quick Start: LUMPI Test Data</h1>
<p>To get started quickly with the LUMPI test data: <br  />
</p><ol type="1">
<li>Download the <a href="https://data.uni-hannover.de:8080/dataset/upload/users/ikg/busch/LUMPI/test_data.zip">LUMPI test data</a></li>
<li>Press the <b>Load</b> button. <br  />
</li>
<li>Choose your <b>ROOT-directory</b>. <br  />
</li>
<li>Select your <b>Label.csv</b> file. <br  />
</li>
<li>Enter your <b>measurementId</b>. <br  />
</li>
</ol>
<hr  />
<p>Use the operational tabs to inspect and work with the data: <br  />
</p>
<h2><a class="anchor" id="autotoc_md6"></a>
&lt;strong&gt;Global View&lt;/strong&gt;</h2>
<p><img src="images/global_view.png" alt="Operational View" class="inline"/> </p>
<ul>
<li>Visualize the entire point cloud with its objects in a large point cloud viewer at the top. <br  />
</li>
<li>Get a global view of the trajectories at the bottom. <br  />
</li>
<li>Interact with objects: <br  />
<ul>
<li><b>Select objects</b>: Use Shift + click in the point cloud view or left-click in the trajectory view. <br  />
</li>
<li><b>Add objects</b>: Click the <b>addObject</b> button and pick points in the global view. <br  />
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md7"></a>
&lt;a href="#operatin:tab"&gt;&lt;strong&gt;Operational View&lt;/strong&gt;&lt;/a&gt;</h2>
<ul>
<li>Visualize a sliding window with multiple views: <br  />
<ul>
<li><b>Point cloud viewer</b> <br  />
</li>
<li><b>Camera viewer</b> <br  />
</li>
<li><b>Bird’s-eye view</b> <br  />
</li>
<li><b>Side view</b> <br  />
</li>
<li><b>Back view</b> (from the object’s perspective for each time step) <br  />
</li>
</ul>
</li>
<li>Modify bounding boxes: <br  />
<ul>
<li><b>Translate position</b> <br  />
</li>
<li><b>Rotate heading</b> <br  />
</li>
</ul>
</li>
<li>Use the context menu for additional actions: <br  />
<ul>
<li>Interpolation <br  />
</li>
<li>Extrapolation <br  />
</li>
<li>Mark as standing <br  />
</li>
<li>Mark/delete overlapping boxes <br  />
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md8"></a>
&lt;strong&gt;Trajectory View&lt;/strong&gt;</h2>
<ul>
<li>Inspect the smoothness of your tracks. <br  />
</li>
<li>Navigate to pose anomalies by left-clicking on a specific pose. <br  />
</li>
</ul>
<h2><a class="anchor" id="autotoc_md9"></a>
&lt;strong&gt;Global Camera View&lt;/strong&gt;</h2>
<p><img src="images/camera_view.png" alt="Operational View" class="inline"/> </p>
<ul>
<li>Observe the entire scene from different perspectives. <br  />
</li>
<li>Select objects by left-clicking. <br  />
</li>
</ul>
<h2><a class="anchor" id="autotoc_md10"></a>
&lt;strong&gt;Model View&lt;/strong&gt;</h2>
<h1><a class="anchor" id="autotoc_md11"></a>
- Inspect the convex hull for the aggregation of all points within the bounding boxes of a track.</h1>
<h1><a class="anchor" id="autotoc_md12"></a>
Best Practice</h1>
<p><b>Summary of best practices for different tasks</b> <br  />
</p>
<h2><a class="anchor" id="autotoc_md13"></a>
Track Extension</h2>
<p>How to start labeling your sensor data or extend your labels with new object tracks. <br  />
 For our recommendations on efficiently adding new tracks, watch this <a href="https://youtu.be/4CFBQkpRbls">tutorial</a>. <br  />
</p>
<ul>
<li>Split existing tracks by clicking <b>split</b> and defining an offset to the existing track. <br  />
<ul>
<li>Add track with astatic offset in front, behind, left or right of a track with identically bounding box dimension.</li>
<li>Split a too big bounding box into two separate parallel moving objects.</li>
</ul>
</li>
<li>Add new objects: <br  />
<ul>
<li>Add objects when they enter the scene. <br  />
</li>
<li>Jump to the point cloud index where they exit the scene and extrapolate the track. <br  />
</li>
<li>Interpolate the track. <br  />
</li>
<li>Go to an index between entry and exit, correct the pose, and interpolate again. <br  />
</li>
<li>Gradually reduce the step size. <br  />
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md14"></a>
Correction</h2>
<p>How to correct tracking errors, track losses, identity switches, and pose jittering for stationary objects. <br  />
 For our recommendations on efficiently fixing tracks, watch this <a href="https://youtu.be/CB34H1LOCZo">tutorial</a>. <br  />
</p>
<ul>
<li>Select the track you want to edit in the <b>Global</b> or <b>Camera</b> tab. <br  />
</li>
<li>Switch to the <b>Operation</b> tab and begin with a high step size. We recommend: <br  />
<ul>
<li><b>Step size 10</b> for vehicles (1 second). <br  />
</li>
<li><b>Step size 20</b> for bicycles (2 second). <br  />
</li>
<li><b>Step size 50</b> for pedestrians (5 second). <br  />
</li>
<li>Increase the step size if the object is stationary. <br  />
</li>
</ul>
</li>
<li>Review the entire track, focusing on the first and last pose: <br  />
<ul>
<li>If the track is too short, extrapolate it until the object is no longer identifiable in the point cloud. <br  />
</li>
<li>If the track is too long or identity switches occurred, use the split option to shorten it. <br  />
</li>
</ul>
</li>
<li>Adjust the box dimensions: <br  />
<ul>
<li>Begin at an index where the object is clearly visible. <br  />
</li>
<li>Verify the dimension size across the entire track, considering the time offset between points. <br  />
</li>
</ul>
</li>
<li>After defining the box size, start pose correction in the <b>Operation</b> tab: <br  />
<ul>
<li>Start with a higher step size, interpolate the track, then gradually reduce the step size until the desired frequence is reached. <br  />
</li>
<li>Use interpolation whenever possible. <br  />
</li>
<li>Mark stationary intervals by clicking **<code>set standing</code>**. <br  />
</li>
<li>Adjust the box in bird’s-eye, side, or back views. <br  />
</li>
<li>Align the heading first for accurate position determination. <br  />
</li>
</ul>
</li>
<li>Check the <b>Trajectory</b> tab for inconsistencies, selecting your desired step size. <br  />
</li>
<li>Generate the image mask by aggregating the points of your track: <br  />
<ul>
<li>Click **<code>generate model</code>** (choose suitable start/end indices and step size; this may take time). <br  />
</li>
</ul>
</li>
<li>Verify the bounding box and mask in the <b>Camera</b> tab. <br  />
</li>
<li>Review multiple objects and longer sequences by saving a video: <br  />
<ul>
<li>Click **<code>generate video</code>** (choose an appropriate interval and frame rate). </li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md15"></a>
Best Practice</h1>
<p><b>Summary of best practices for different tasks</b> <br  />
</p>
<h2><a class="anchor" id="autotoc_md16"></a>
Track Extension</h2>
<p>How to start labeling your sensor data or extend your labels with new object tracks. <br  />
 For our recommendations on efficiently adding new tracks, watch this <a href="https://youtu.be/4CFBQkpRbls">tutorial</a>. <br  />
</p>
<ul>
<li>Split existing tracks by clicking <b>split</b> and defining an offset to the existing track. <br  />
<ul>
<li>Add a track with a static offset in front, behind, left, or right of a track with identical bounding box dimensions. <br  />
</li>
<li>Split a too large bounding box into two separate parallel moving objects. <br  />
</li>
</ul>
</li>
<li>Add new objects: <br  />
<ul>
<li>Add objects when they enter the scene. <br  />
</li>
<li>Jump to the point cloud index where they exit the scene and extrapolate the track. <br  />
</li>
<li>Interpolate the track. <br  />
</li>
<li>Go to an index between entry and exit, correct the pose, and interpolate again. <br  />
</li>
<li>Gradually reduce the step size. <br  />
</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md17"></a>
Correction</h2>
<p>How to correct tracking errors, track losses, identity switches, and pose jittering for stationary objects. <br  />
 For our recommendations on efficiently fixing tracks, watch this <a href="https://youtu.be/CB34H1LOCZo">tutorial</a>. <br  />
</p>
<ul>
<li>Select the track you want to edit in the <b>Global</b> or <b>Camera</b> tab. <br  />
</li>
<li>Switch to the <b>Operation</b> tab and begin with a high step size. We recommend: <br  />
<ul>
<li><b>Step size 10</b> for vehicles (1 second). <br  />
</li>
<li><b>Step size 20</b> for bicycles (2 seconds). <br  />
</li>
<li><b>Step size 50</b> for pedestrians (5 seconds). <br  />
</li>
<li>Increase the step size if the object is stationary. <br  />
</li>
</ul>
</li>
<li>Review the entire track, focusing on the first and last pose: <br  />
<ul>
<li>If the track is too short, extrapolate it until the object is no longer identifiable in the point cloud. <br  />
</li>
<li>If the track is too long or identity switches occurred, use the split option to shorten it. <br  />
</li>
</ul>
</li>
<li>Adjust the box dimensions: <br  />
<ul>
<li>Begin at an index where the object is clearly visible. <br  />
</li>
<li>Verify the dimension size across the entire track, considering the time offset between points. <br  />
</li>
</ul>
</li>
<li>After defining the box size, start pose correction in the <b>Operation</b> tab: <br  />
<ul>
<li>Start with a higher step size, interpolate the track, then gradually reduce the step size until the desired frequency is reached. <br  />
</li>
<li>Use interpolation whenever possible. <br  />
</li>
<li>Mark stationary intervals by clicking <code>set standing</code>. <br  />
</li>
<li>Adjust the box in bird’s-eye, side, or back views. <br  />
</li>
<li>Align the heading first for accurate position determination. <br  />
</li>
</ul>
</li>
<li>Check the <b>Trajectory</b> tab for inconsistencies, selecting your desired step size. <br  />
</li>
<li>Generate the image mask by aggregating the points of your track: <br  />
<ul>
<li>Click <b>generate model</b> (choose suitable start/end indices and step size; this may take time). <br  />
</li>
</ul>
</li>
<li>Verify the bounding box and mask in the <b>Camera</b> tab. <br  />
</li>
<li>Review multiple objects and longer sequences by saving a video: <br  />
<ul>
<li>Click <b>generate video</b> (choose an appropriate interval and frame rate). <br  />
</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md18"></a>
Adaptation</h1>
<p>Feel free to adapt the code to suit your specific requirements and data. Below, we outline simple modifications to customize the tool: <br  />
</p>
<h2><a class="anchor" id="autotoc_md19"></a>
Sliding Window: Count and Width</h2>
<p>To change the size of the sliding window and adjust the number of columns in the operational view: <br  />
</p><ol type="1">
<li>Modify the **<code>slidingWindow</code>** variable to set the desired number of columns. <br  />
<ul>
<li>Note: Adjusting this variable does not change the column width. If the content exceeds the available space, a scroll bar will be added automatically. <br  />
</li>
</ul>
</li>
<li>To adjust the column width, modify the **<code>columnViewSize</code>** variable. <br  />
<ul>
<li>This variable dynamically adapts based on the main window size. <br  />
</li>
<li>For further customization, review the <code>set_model_view_dimensions()</code> method in the <code>LabelingPresenter</code> class. <br  />
 &lt;details&gt;</li>
</ul>
</li>
</ol>
<p><br  />
</p>
<div class="fragment"><div class="line">void LabelingPresenter::set_model_view_dimensions() {</div>
<div class="line">    model.singleTrajectoryWidth = view-&gt;width() / 6. * 5;# A sixth of the window width is reserved for the operation button panel.</div>
<div class="line">    model.singleTrajectoryHeight = view-&gt;height();</div>
<div class="line">    model.globalTrajectoryWidth = view-&gt;width() / 6. * 5;</div>
<div class="line">    model.globalTrajectoryHeight = view-&gt;height() / 3;</div>
<div class="line">    model.rowViewSize = view-&gt;height() / 6.;</div>
<div class="line">    model.columViewSize = view-&gt;width() / 6.;</div>
<div class="line">}</div>
</div><!-- fragment --><p>&lt;/details&gt;</p>
<h2><a class="anchor" id="autotoc_md20"></a>
Point Cloud Input</h2>
<p>To use different point cloud data, simply modify the **<code>get_cloud(int)</code>** method by replacing the parsing line with your custom point cloud parser: <br  />
 &lt;details&gt;</p>
<p>Code replacement </p>
<p><br  />
</p>
<div class="fragment"><div class="line"># Labeling.cpp Line 532:</div>
<div class="line">---   tmpCloud.second= Parser::load_cloud_ikg_benchmark(ss.str());</div>
<div class="line"> </div>
<div class="line">    /* Example: replace the loading method with the following code to load a mobile mapping cloud from the institute for Cartography and Geoinformatics:</div>
<div class="line">    tmpCloud.second= Parser::load_cloud_ikg_mobile_mapping(&quot;../mobile_mapping/003.ply&quot;);</div>
<div class="line">    cv::Point3d center(0,0,0);</div>
<div class="line">    for(auto&amp;p:tmpCloud.second){</div>
<div class="line">        center.x+=p.x;</div>
<div class="line">        center.y+=p.y;</div>
<div class="line">        center.z+=p.z;</div>
<div class="line">    }</div>
<div class="line">    center/=(double)tmpCloud.second.size();</div>
<div class="line">    for(auto &amp;p:tmpCloud.second){</div>
<div class="line">        p.x-=center.x;</div>
<div class="line">        p.y-=center.y;</div>
<div class="line">        p.z-=center.z;</div>
<div class="line">    }</div>
<div class="line">    */</div>
</div><!-- fragment --><p>&lt;/details&gt; The Parser.cpp class should give you some insperatin of how to write your own point cloud parser. The core functionality is given also for only XYZ information. If you want to change the index scheme, have a closer look to this method. <br  />
</p>
<h2><a class="anchor" id="autotoc_md21"></a>
Camera Input</h2>
<p>We recommend using cameras, especially in crowded scenes, where identity switches can be challenging to detect using point clouds alone. <br  />
</p>
<p>To incorporate camera data, the extrinsic and intrinsic parameters for each camera perspective must be known. The LiDAR frame serves as the main coordinate frame, and all labels will also be saved in this frame. Camera images are loaded as one video per camera, following the expected <a href="#structure">file structure</a>. <br  />
</p>
<p>The camera metadata is loaded from the <code>meta.json</code> file, which should include the following information: <br  />
</p><ul>
<li>**Experiment/Measurement ID (<code>experimentId</code>)**: Identifies the correct subfolder within your <b>ROOT</b> directory. <br  />
</li>
<li>**Camera Device ID (<code>deviceId</code>)**: Specifies and locates the corresponding video. <br  />
</li>
<li>**Camera Intrinsics (<code>intrinsic</code>)**: A 3x3 matrix representing the camera’s intrinsic parameters. <br  />
</li>
<li>**Camera Rotation (<code>rvec</code>)**: A 3x1 vector defining the rotation from the LiDAR to the camera. <br  />
</li>
<li>**Camera Translation (<code>tvec</code>)**: A 3x1 vector defining the translation from the LiDAR to the camera. <br  />
</li>
<li>**Camera Distortion (<code>distortion</code>)**: A 4x1 vector accounting for lens distortion. <br  />
</li>
<li>**Camera Frames Per Second (<code>fps</code>)**: Used for time synchronization. <br  />
</li>
</ul>
<h2><a class="anchor" id="autotoc_md22"></a>
Time Synchronization</h2>
<p>For time synchronization purposes, it is assumed that all videos start simultaneously. To synchronize the LiDAR data with the videos, point clouds are stored with a continuous index, represented by filenames with leading zeros.</p>
<p>The highest accuracy is achieved by using a timestamp for each scanned point, allowing precise alignment of the point cloud with the camera data. A per-point timestamp is used to subsample the point cloud, enabling more accurate determination of pose timestamps and improved interpolation of labels into the camera frames. This is particularly crucial if you intend to use LiDAR data to generate training datasets for camera-based detection. Therefore, we strongly recommend using a timestamp for each point.</p>
<p>If you choose to use this tool without per-point timestamps, you must disable pose time adaptation in the modeling process as well as heat map coloring in the bird’s-eye, side, and back views. To do this, modify the methods <code>generate_back_view(int,int)</code>, <code>generate_top_view(int,int)</code>, and <code>generate_side_view(int,int)</code> by removing the time collection loop:</p>
<p>&lt;details&gt;</p>
<p>Code replacement </p>
<p><br  />
</p>
<div class="fragment"><div class="line">--- cv::Mat times(within.size(), 1, CV_64F, cv::Scalar(0));</div>
<div class="line">---     for (int i = 0; i &lt; within.size(); i++) {</div>
<div class="line">---         times.at&lt;double&gt;(i, 0) = within[i].adjustedtime;</div>
<div class="line">---     }</div>
<div class="line">---       auto heat = ikg::Plotter::get_heat_map(times);</div>
<div class="line">....</div>
<div class="line">....</div>
<div class="line">---    cv::circle(tv, p3, pointSize, heat.at&lt;cv::Vec3b&gt;(i, 0), -1);</div>
<div class="line">+++     cv::circle(tv, p3, pointSize, cv::Scalar(0,255,0), -1);</div>
</div><!-- fragment --><p>&lt;/details&gt;</p>
<p>Finally delete the time adaption in the <code>aggregate_points(...)</code> method: &lt;details&gt;</p>
<p>Code replacement </p>
<div class="fragment"><div class="line">---         times.push_back(pc.points[i].adjustedtime);</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">---     double th = 0.01 * sec2msec;</div>
<div class="line">---     sort(times.begin(), times.end());</div>
<div class="line">---     vector&lt;vector&lt;double&gt;&gt; segments(1);</div>
<div class="line">---     segments.back().push_back(times.front());</div>
<div class="line">---     for (int i = 1; i &lt; times.size(); i++) {</div>
<div class="line">---         if (times[i] - times[i - 1] &gt; th) {</div>
<div class="line">---             segments.push_back(vector&lt;double&gt;());</div>
<div class="line">---         }</div>
<div class="line">---         segments.back().push_back(times[i]);</div>
<div class="line">---     }</div>
<div class="line">---sort(segments.begin(), segments.end(), [](auto const &amp;a, auto const &amp;b) {</div>
<div class="line">---         return a.size() &gt; b.size();</div>
<div class="line">---     });</div>
<div class="line">---     p.time = accumulate(segments.front().begin(), segments.front().end(), 0.) / (double) segments.front().size()*msec2sec;</div>
<div class="line">---     p.visibility=times.size();</div>
</div><!-- fragment --><p>&lt;/details&gt;</p>
<h1><a class="anchor" id="autotoc_md23"></a>
Development</h1>
<p>If you are intressted in the development of this tool please contact <a href="#" onclick="location.href='mai'+'lto:'+'ste'+'ff'+'en.'+'bu'+'sch'+'@i'+'kg.'+'un'+'i-h'+'an'+'nov'+'er'+'.de'; return false;">me</a>.</p>
<h1><a class="anchor" id="autotoc_md24"></a>
License</h1>
<p>This project is dual-licensed under the following licenses:</p>
<h2><a class="anchor" id="autotoc_md25"></a>
Public License</h2>
<p>This project is licensed under the GNU Affero General Public License (AGPLv3). You can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p>
<p>For more details, see the [LICENSE-AGPLv3](LICENSE-AGPLv3) file or visit <a href="https://www.gnu.org/licenses/agpl-3.0.html">https://www.gnu.org/licenses/agpl-3.0.html</a>.</p>
<h2><a class="anchor" id="autotoc_md26"></a>
Commercial License</h2>
<p>For commercial use, please contact the project authors to obtain a commercial license. The commercial license allows you to use the project in proprietary software and provides additional benefits such as support and maintenance.</p>
<p>For inquiries regarding the commercial license, please contact <a href="#" onclick="location.href='mai'+'lto:'+'ste'+'ff'+'en.'+'bu'+'sch'+'@i'+'kg.'+'un'+'i-h'+'an'+'nov'+'er'+'.de'; return false;">me</a>. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
